{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 1.6456213  -0.58993244 -1.471175   -0.35517454 -4.663396    1.8467236\n",
      "  2.4011745   3.7244453  -2.7367365  -2.7680314  -1.8961191   2.2233582\n",
      " -3.6681283   0.4806385   0.746088    3.9968348  -4.905363    0.21230698\n",
      "  1.3454447  -3.006717  ], shape=(20,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train = tf.random.uniform(shape=[20], minval=-5, maxval=5)\n",
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=<tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
      "array([1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
      "      dtype=int64)>\n"
     ]
    }
   ],
   "source": [
    "label = tf.greater(train, 0)\n",
    "label = tf.cast(label, dtype=tf.int64)\n",
    "print(f\"{label=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val.numpy()=3.9968348\tmin_val.numpy()=-4.905363\n",
      "\n",
      "norm_train=<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
      "array([ 0.13957603, -0.05003608, -0.12478009, -0.0301247 , -0.39553347,\n",
      "        0.15663286,  0.2036595 ,  0.31589487, -0.23212074, -0.23477507,\n",
      "       -0.16082242,  0.18857773, -0.31111825,  0.04076613,  0.06328066,\n",
      "        0.33899802, -0.4160563 ,  0.01800716,  0.11411607, -0.25501958],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "max_val = tf.reduce_max(train)\n",
    "min_val = tf.reduce_min(train)\n",
    "print(f\"{max_val.numpy()=}\\t{min_val.numpy()=}\\n\")\n",
    "\n",
    "norm_train = tf.squeeze(tf.keras.utils.normalize(train, axis = 0))\n",
    "print(f\"{norm_train=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(dataset.as_numpy_iterator())=[(0.13957603, 1.0), (-0.050036076, 0.0), (-0.12478009, 0.0), (-0.030124703, 0.0), (-0.39553347, 0.0), (0.15663286, 1.0), (0.2036595, 1.0), (0.31589487, 1.0), (-0.23212074, 0.0), (-0.23477507, 0.0), (-0.16082242, 0.0), (0.18857773, 1.0), (-0.31111825, 0.0), (0.040766135, 1.0), (0.063280664, 1.0), (0.33899802, 1.0), (-0.4160563, 0.0), (0.01800716, 1.0), (0.11411607, 1.0), (-0.25501958, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((norm_train, tf.cast(label, tf.float32)))\n",
    "print(f\"{list(dataset.as_numpy_iterator())=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: [-0.23212074 -0.23477507 -0.16082242  0.18857773]\tlable: [0. 0. 0. 1.]\n",
      "feature: [ 0.13957603 -0.05003608 -0.12478009 -0.0301247 ]\tlable: [1. 0. 0. 0.]\n",
      "feature: [-0.39553347  0.15663286  0.2036595   0.31589487]\tlable: [0. 1. 1. 1.]\n",
      "feature: [-0.4160563   0.01800716  0.11411607 -0.25501958]\tlable: [0. 1. 1. 0.]\n",
      "feature: [-0.31111825  0.04076613  0.06328066  0.33899802]\tlable: [0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# With batch size of 4, batch the transformed dataset; then shuffle it\n",
    "for batch in dataset.batch(4).shuffle(buffer_size=len(dataset)):\n",
    "    print(f\"feature: {batch[0].numpy()}\\tlable: {batch[1].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: [ 0.13957603 -0.05003608 -0.12478009 -0.0301247 ]\tlable: [1. 0. 0. 0.]\n",
      "feature: [-0.23212074 -0.23477507 -0.16082242  0.18857773]\tlable: [0. 0. 0. 1.]\n",
      "feature: [-0.4160563   0.01800716  0.11411607 -0.25501958]\tlable: [0. 1. 1. 0.]\n",
      "feature: [-0.39553347  0.15663286  0.2036595   0.31589487]\tlable: [0. 1. 1. 1.]\n",
      "feature: [-0.31111825  0.04076613  0.06328066  0.33899802]\tlable: [0. 1. 1. 1.]\n",
      "feature: [-0.4160563   0.01800716  0.11411607 -0.25501958]\tlable: [0. 1. 1. 0.]\n",
      "feature: [-0.31111825  0.04076613  0.06328066  0.33899802]\tlable: [0. 1. 1. 1.]\n",
      "feature: [-0.23212074 -0.23477507 -0.16082242  0.18857773]\tlable: [0. 0. 0. 1.]\n",
      "feature: [ 0.13957603 -0.05003608 -0.12478009 -0.0301247 ]\tlable: [1. 0. 0. 0.]\n",
      "feature: [-0.39553347  0.15663286  0.2036595   0.31589487]\tlable: [0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Repeat the batched dataset so that each batch will be trained \"twice\"\n",
    "for batch in dataset.batch(4).repeat(2).shuffle(buffer_size=len(dataset)):\n",
    "    print(f\"feature: {batch[0].numpy()}\\tlable: {batch[1].numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
